{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4fqP9NQyXhg"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "#stop_words = set(stopwords.words('english'))\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from itertools import chain\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "metadata": {
        "id": "sOvmxpHGxofh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98ecc1e-239d-43cf-bf76-2acc238ef237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scikit-learn version is 1.2.2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhxTZqZuwKwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75ebad4-c3e0-4320-c72d-234d02e798a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prvWX5nNORf4"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndmr_Jagv6wi"
      },
      "outputs": [],
      "source": [
        "def get_root(phrase):\n",
        "  for token in phrase:\n",
        "    if token.dep_ == 'ROOT':\n",
        "      return token\n",
        "\n",
        "#takes a phrase as input in the tokenized fromat\n",
        "#breadth-first search of the dependency tree of the given phrase\n",
        "#returns a the dictionary with the length of the path to root for each token in the sentence\n",
        "def len_path_root(phrase):\n",
        "  dist = 0\n",
        "  root_token = get_root(phrase)\n",
        "  children = list(root_token.children)\n",
        "  lengths = {\n",
        "      root_token: dist\n",
        "  }\n",
        "  children_count = len(list(children))\n",
        "  while children_count != 0:\n",
        "    dist += 1\n",
        "    new_children = []\n",
        "    for token in children:\n",
        "      lengths[token] = dist\n",
        "      new_children.extend(token.children)\n",
        "    children=new_children\n",
        "    children_count = len(list(new_children))\n",
        "\n",
        "  #assign length -1 (chosen randomly) for nodes not connected to the root\n",
        "  for token in phrase:\n",
        "    if token not in lengths:\n",
        "      lengths[token] = -1\n",
        "\n",
        "  return lengths\n",
        "\n",
        "#takes the dataset, phrase_id and chapter_id\n",
        "#retruns the phrase in a string by merging the words\n",
        "#used to iterate in the training and testing set for extracting phrases\n",
        "def get_text(table, id,chapter):\n",
        "  phrase_table = table[(table['phrase_id'] == id) & (table['chapter_id'] == chapter)]\n",
        "  return ' '.join(join_punctuation(phrase_table['word'].values))\n",
        "\n",
        "def join_punctuation(seq, characters='.,;?!'):\n",
        "    characters = set(characters)\n",
        "    seq = iter(seq)\n",
        "    current = next(seq)\n",
        "\n",
        "    for nxt in seq:\n",
        "        if nxt in characters:\n",
        "            current += nxt\n",
        "        else:\n",
        "            yield current\n",
        "            current = nxt\n",
        "\n",
        "    yield current\n",
        "\n",
        "# def get_text(table, id,chapter):\n",
        "#   phrase_table = table[(table['phrase_id'] == id) & (table['chapter_id'] == chapter)]\n",
        "#   return ' '.join(phrase_table['word'].values)\n",
        "\n",
        "#returns a list with the labels of a phrase identified with the ch_id, and phr_id\n",
        "def get_labels(table, id,chapter):\n",
        "  phrase_table = table[(table['phrase_id'] == id) & (table['chapter_id'] == chapter)]\n",
        "  return phrase_table['label'].values\n",
        "\n",
        "#adjusted lemmatization for nltk library\n",
        "#offers the POS as a parameter to lemmatization function to make it more precise\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "#used to match the length of the tokenization with the length of the filtered table\n",
        "#initially implemented for the previous assignment of data preprocessing\n",
        "#treats separately some excpetions found\n",
        "def tokenize(arg, ch = 'baskervilles03', ph = 21):\n",
        "\n",
        "  if (ph, ch) == (436, 'wisteria02'):\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[0:2])\n",
        "      retokenizer.merge(arg[4:7])\n",
        "    return arg\n",
        "\n",
        "  if (ph, ch) in [(450, 'cardboard'),(457, 'cardboard')]:\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[2:4])\n",
        "      retokenizer.merge(arg[0:2])\n",
        "    return arg\n",
        "\n",
        "\n",
        "  no_exc = [('baskervilles03', 16), ('baskervilles03', 20), ('baskervilles11', 45), ('baskervilles12', 283), ('baskervilles13', 271), ('baskervilles14', 55)]\n",
        "  retok1_pos = []#for -\n",
        "  retok2_pos = []#for `\n",
        "\n",
        "  #1\n",
        "  shift = 0\n",
        "  cr_pos = 0\n",
        "  for token in arg:\n",
        "    if token.text == '-':\n",
        "      retok1_pos.append(cr_pos)\n",
        "    cr_pos+=1\n",
        "    prev_char = token.text\n",
        "\n",
        "  for pos in retok1_pos:\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[pos-1-shift:pos+2-shift])\n",
        "      shift += 2\n",
        "\n",
        "  #2\n",
        "  shift = 0\n",
        "  cr_pos = 0\n",
        "  prev_char = 0\n",
        "  for token in arg:\n",
        "    if token.text =='`' and prev_char == '`':\n",
        "      retok2_pos.append(cr_pos)\n",
        "    cr_pos+=1\n",
        "    prev_char = token.text\n",
        "\n",
        "  for pos in retok2_pos:\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[pos-shift-1:pos+1-shift])\n",
        "      shift += 1\n",
        "\n",
        "  #3\n",
        "  retok2_pos = []\n",
        "  suf = ['66', '86','ve','m']\n",
        "  shift = 0\n",
        "  cr_pos = 0\n",
        "  prev_char = 0\n",
        "  for token in arg:\n",
        "    if token.text in suf and prev_char == \"'\" or token.text == '.' and prev_char == \"No\" and (ch,ph) not in no_exc:\n",
        "      retok2_pos.append(cr_pos)\n",
        "    cr_pos+=1\n",
        "    prev_char = token.text\n",
        "\n",
        "  for pos in retok2_pos:\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[pos-shift-1:pos+1-shift])\n",
        "      shift += 1\n",
        "\n",
        "  if ph in [0,'0']:\n",
        "    with arg.retokenize() as retokenizer:\n",
        "      retokenizer.merge(arg[2:4])\n",
        "\n",
        "\n",
        "  return arg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyc_QQ8XSKgt"
      },
      "source": [
        "## [Not needed anymore] Testing attributes on individual pre-set phrase before automatically adding to the table dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "GJAAaSh264RX",
        "outputId": "6c074eb9-6af8-42cf-f3ee-abd938674169"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-320a7629260e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#testing if tokenize and data from table have the same length for each phrase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_ch_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_ch_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfilter_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chapter_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ],
      "source": [
        "#testing if tokenize and data from table have the same length for each phrase\n",
        "all_ch_ids = train_data['chapter_id'].unique()\n",
        "mismatch=[]\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = train_data[train_data['chapter_id'] == ch]\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  for ph in all_ph_ids:\n",
        "    filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "    phrase = get_text(ph, ch)\n",
        "    phr_doc = nlp(phrase)\n",
        "    tok = tokenize(phr_doc, ch, ph)\n",
        "    if len(filter_ph) != len(tok):\n",
        "      mismatch.append((ch,ph))\n",
        "print(len(mismatch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QhrBL7XXqgm"
      },
      "outputs": [],
      "source": [
        "#testing if there is any negation in\n",
        "all_ch_ids = train_data['chapter_id'].unique()\n",
        "mismatch=[]\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = train_data[train_data['chapter_id'] == ch]\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  for ph in all_ph_ids:\n",
        "    filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "    phrase = get_text(ph, ch)\n",
        "    phr_doc = nlp(phrase)\n",
        "    tok = tokenize(phr_doc, ch, ph)\n",
        "    if len(filter_ph) != len(tok):\n",
        "      mismatch.append((ch,ph))\n",
        "print(len(mismatch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4jSB2po4otL"
      },
      "outputs": [],
      "source": [
        "#errors\n",
        "phrase = get_text(436, 'wisteria02')\n",
        "phr_doc = nlp(phrase)\n",
        "#toks = tokenize(phr_doc,436)\n",
        "for tok in phr_doc:\n",
        "  print(tok,'\\n')\n",
        "\n",
        "# flag = 0\n",
        "# if(all(x in abc for x in mismatch)):\n",
        "#     flag = 1\n",
        "# print(flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_moUSU35c59d"
      },
      "outputs": [],
      "source": [
        "#nbor(d) - neighbour in the initial sentence at distance d -/+ -> to left/right\n",
        "phr1 = \"He is interested in learning Natural Language Processing.\"\n",
        "phr2 = \"I stood upon the hearth-rug and picked up the stick which our visitor had left behind him the night before.\"\n",
        "phr3 = \"Gus Proto is a Python developer currently working for a London-based Fintech company\"\n",
        "\n",
        "phr_doc = nlp(phr2)\n",
        "res = len_path_root(phr_doc)\n",
        "\n",
        "for token in phr_doc:\n",
        "  print(token.text, res[token], \"\\n\")\n",
        "\n",
        "displacy.render(phr_doc, style=\"dep\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJdzOnF1AGVY"
      },
      "outputs": [],
      "source": [
        "phr4 = \"Mr. Sherlock Holmes , who was usually very late in the mornings , save upon those not infrequent occasions when he was up all night , was seated at the breakfast table .\"\n",
        "phr4 = \"guru99 is a totally new kind of learning experience.\"\n",
        "phr4 = \"The striped bats are hanging on their feet for best\"\n",
        "\n",
        "#phr4 = sent_tokenize(phr4)\n",
        "words_list = nltk.word_tokenize(phr4)\n",
        "print(tokenize(words_list))\n",
        "print(words_list)\n",
        "#adjusted lemma\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words_list])\n",
        "\n",
        "#POS 1,2\n",
        "# fine_tags = nltk.pos_tag(words_list)\n",
        "# coarse_tags = nltk.pos_tag(words_list, tagset='universal')\n",
        "# print(fine_tags)\n",
        "# print(coarse_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue9yXRR9-HuZ"
      },
      "outputs": [],
      "source": [
        "id = 15\n",
        "ch = 'baskervilles01'\n",
        "txt = get_text(id,ch)\n",
        "txt = \"I wouldn't do that\"\n",
        "phr_doc = nlp(txt)\n",
        "\n",
        "#print(len(list(phr_doc)))\n",
        "\n",
        "# with phr_doc.retokenize() as retokenizer:\n",
        "#     retokenizer.merge(phr_doc[21:23])\n",
        "\n",
        "#phr_doc = re_tokenize(phr_doc)\n",
        "for token in phr_doc:\n",
        "  print(token)\n",
        "\n",
        "#displacy.render(phr_doc, style=\"dep\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLCw19tK1Cvy"
      },
      "outputs": [],
      "source": [
        "#backup\n",
        "def sent2feature(sentence, ch = 'baskervilles03', ph = 21):\n",
        "  sent_feat = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  sent_doc = nlp(sentence)\n",
        "  tokens = tokenize(sent_doc, ch, ph)\n",
        "  lengths = len_path_root(tokens)\n",
        "\n",
        "  ord = 0\n",
        "  shift = 0\n",
        "  for tok in tokens:\n",
        "    features = word2feature(tok)\n",
        "    features['len_path_root'] = lengths[tok]\n",
        "    sent_feat.append(features)\n",
        "\n",
        "  return sent_feat\n",
        "\n",
        "def process_data(table):\n",
        "  all_ch_ids = table['chapter_id'].unique()\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "  for ch in all_ch_ids:\n",
        "    filter_ch = table[table['chapter_id'] == ch]\n",
        "    all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "    for ph in all_ph_ids:\n",
        "      filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "      phrase = get_text(table, ph, ch)\n",
        "      labels = get_labels(table, ph, ch)\n",
        "      all_features.append(sent2feature(phrase, ch, ph))\n",
        "      all_labels.append(labels)\n",
        "\n",
        "  return all_features, all_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7d-MsmDOeCX"
      },
      "source": [
        "## Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bViK7iTB7jLq"
      },
      "outputs": [],
      "source": [
        "#merging test datasets\n",
        "test_card = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/ATM/SEM-2012-test-cardboard.txt', sep=\"\\t\", header = None)\n",
        "test_circ = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/ATM/SEM-2012-test-circle.txt', sep=\"\\t\", header = None)\n",
        "\n",
        "frames = [test_card, test_circ]\n",
        "test_data = pd.concat(frames)\n",
        "test_data.rename(columns={1: 'phrase_id', 0: 'chapter_id', 2:'word_id', 3:'word', 4:'label'}, inplace=True)\n",
        "#print(test_data.head(40))\n",
        "\n",
        "#train & dev\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/ATM/SEM-2012-training.txt', sep=\"\\t\", header = None)\n",
        "dev = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/ATM/SEM-2012-dev.txt', sep=\"\\t\", header = None)\n",
        "\n",
        "train_data.rename(columns={1: 'phrase_id', 0: 'chapter_id', 2:'word_id', 3:'word', 4:'label'}, inplace=True)\n",
        "dev.rename(columns={1: 'phrase_id', 0: 'chapter_id', 2:'word_id', 3:'word', 4:'label'}, inplace=True)\n",
        "\n",
        "#print(dev.head(10))\n",
        "#counting B-Neg values\n",
        "#print(train_data['label'].value_counts()['B-NEG'])\n",
        "\n",
        "#merged datasets in test_data; train_data and dev separate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcQPgzSOkyCZ"
      },
      "source": [
        "## Dataset exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pch_WI7txN1z",
        "outputId": "7aaca6f2-6380-4fae-f092-b75b4b14b4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['baskervilles01' 'baskervilles02' 'baskervilles03' 'baskervilles04'\n",
            " 'baskervilles05' 'baskervilles06' 'baskervilles07' 'baskervilles08'\n",
            " 'baskervilles09' 'baskervilles10' 'baskervilles11' 'baskervilles12'\n",
            " 'baskervilles13' 'baskervilles14' 'wisteria01' 'wisteria02']\n"
          ]
        }
      ],
      "source": [
        "all_ch_ids = train_data['chapter_id'].unique()\n",
        "print(all_ch_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of phrases/chapter\n",
        "all_ch_ids = dev['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = dev[dev['chapter_id'] == ch]\n",
        "  #print(len(filter_ch))\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  print(len(all_ph_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLjuY2BwAIXP",
        "outputId": "d56a79fc-5fdb-4439-f706-d47e4558ee7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347\n",
            "440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr-rHortyOJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd8f5b5-4ad8-450d-b8c9-a228741c60eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3644\n"
          ]
        }
      ],
      "source": [
        "#number of phrases/chapter\n",
        "all_ch_ids = train_data['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "abc=[]\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = train_data[train_data['chapter_id'] == ch]\n",
        "  #print(len(filter_ch))\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  abc.append(len(all_ph_ids))\n",
        "print(sum(abc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ch_ids = test_data['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = test_data[test_data['chapter_id'] == ch]\n",
        "  #print(len(filter_ch))\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  print(len(all_ph_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JyDTX6P9cgs",
        "outputId": "572647dc-bd9a-494d-8ed4-4c1dfd4ba2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "496\n",
            "371\n",
            "222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akPDVdZlkv82",
        "outputId": "f2c11bb0-e6ef-433c-f01f-3a1e203dc850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n",
            "2\n",
            "17.961306256860592\n"
          ]
        }
      ],
      "source": [
        "#num chapters training\n",
        "phrase_lengths = []\n",
        "\n",
        "all_ch_ids = train_data['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = train_data[train_data['chapter_id'] == ch]\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  for ph in all_ph_ids:\n",
        "    filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "    phrase_lengths.append(len(filter_ph))\n",
        "\n",
        "print(max(phrase_lengths))\n",
        "print(min(phrase_lengths))\n",
        "print(sum(phrase_lengths) / len(phrase_lengths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRtADJDu19X-",
        "outputId": "c8889f8d-a789-49e5-f7c9-3ed5da4a30df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68\n",
            "2\n",
            "17.6455463728191\n"
          ]
        }
      ],
      "source": [
        "phrase_lengths = []\n",
        "\n",
        "all_ch_ids = test_data['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = test_data[test_data['chapter_id'] == ch]\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  for ph in all_ph_ids:\n",
        "    filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "    phrase_lengths.append(len(filter_ph))\n",
        "\n",
        "print(max(phrase_lengths))\n",
        "print(min(phrase_lengths))\n",
        "print(sum(phrase_lengths) / len(phrase_lengths))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase_lengths = []\n",
        "\n",
        "all_ch_ids = dev['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = dev[dev['chapter_id'] == ch]\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  for ph in all_ph_ids:\n",
        "    filter_ph = filter_ch[filter_ch['phrase_id'] == ph]\n",
        "    phrase_lengths.append(len(filter_ph))\n",
        "\n",
        "print(max(phrase_lengths))\n",
        "print(min(phrase_lengths))\n",
        "print(sum(phrase_lengths) / len(phrase_lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-4eqyMTCjux",
        "outputId": "55277dbd-8dc4-48ab-f27c-5c1dab1ce3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n",
            "2\n",
            "17.238881829733163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G5i7Uo91Gj7",
        "outputId": "33cc56c1-8fae-46d7-8790-de5a60572300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65451\n",
            "13567\n",
            "19216\n"
          ]
        }
      ],
      "source": [
        "print(len(train_data))\n",
        "print(len(dev))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ERpOk813Fz",
        "outputId": "8b99d712-4728-4811-9fc0-cb03af38a2f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cardboard' 'circle01' 'circle02']\n"
          ]
        }
      ],
      "source": [
        "all_ch_ids = test_data['chapter_id'].unique()\n",
        "print(all_ch_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV2IjaVb14yp",
        "outputId": "f32bdefd-6a63-4176-870e-b651b31780f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "496\n",
            "371\n",
            "222\n"
          ]
        }
      ],
      "source": [
        "all_ch_ids = test_data['chapter_id'].unique()\n",
        "all_features = []\n",
        "all_labels = []\n",
        "for ch in all_ch_ids:\n",
        "  filter_ch = test_data[test_data['chapter_id'] == ch]\n",
        "  #print(len(filter_ch))\n",
        "  all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "  print(len(all_ph_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQWknNlg6j6r"
      },
      "outputs": [],
      "source": [
        "print(list(train_data['label'].values).count('B-NEG'))\n",
        "print(list(train_data['label'].values).count('I-NEG'))\n",
        "print(list(train_data['label'].values).count('O'))\n",
        "\n",
        "print('\\n', \"dev\")\n",
        "print(list(dev['label'].values).count('B-NEG'))\n",
        "print(list(dev['label'].values).count('I-NEG'))\n",
        "print(list(dev['label'].values).count('O'))\n",
        "\n",
        "print('\\n', \"test\")\n",
        "print(list(test_data['label'].values).count('B-NEG'))\n",
        "print(list(test_data['label'].values).count('I-NEG'))\n",
        "print(list(test_data['label'].values).count('O'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR5-pL5miPhX"
      },
      "source": [
        "## CRF functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXnUKNHQ-fAE"
      },
      "outputs": [],
      "source": [
        "#takes a token as input\n",
        "#returns True if token should be kept, or False if it is filtered\n",
        "#could be changed depending on performance\n",
        "def keep(tok):\n",
        "  neg_list = ['nor', 'Nor', 'neither', 'Neither', 'without', 'Without', 'nobody', 'Nobody', 'none', 'None', 'nothing', 'Nothing',\n",
        "            'never', 'not', 'no', 'Never', 'Not', 'No', 'nowhere', 'non', 'Nowhere', 'Non', \"n't\", \"rather\", \"than\", 'for', 'the']\n",
        "  if tok.text in neg_list:\n",
        "    return True\n",
        "  # if tok.is_punct or tok.is_stop or tok.text == \"``\":\n",
        "  if tok.is_punct or tok.text == \"``\":\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def word2feature(token):\n",
        "  prefixes = ['un', 'in', 'im','il', 'dis', 'non', 'ir',\n",
        "              'Un', 'In', 'Im','Il', 'Dis', 'Non', 'Ir']\n",
        "\n",
        "  pref = 0\n",
        "  for p in prefixes:\n",
        "    if token.text.startswith(p):\n",
        "      pref = 1\n",
        "      break\n",
        "\n",
        "  suf = 0\n",
        "  if 'less' in token.text:\n",
        "    suf = 1\n",
        "\n",
        "  #for feature selection the unwanted features can be commented\n",
        "  features = {\n",
        "    'text': token.text,\n",
        "    'lemma':token.lemma_,\n",
        "    'fine_pos': token.pos_,\n",
        "    'coarse_pos': token.tag_,\n",
        "    'dependency':token.dep_,\n",
        "    #'head':token.head.text,\n",
        "    'suffix':suf,\n",
        "    'prefix': pref\n",
        "  }\n",
        "\n",
        "  return features\n",
        "\n",
        "#takes as input text of a sentence\n",
        "#returns a list of dictionaries with the features of its tokens\n",
        "def sent2feature(sentence, labels, is_test, ch = 'baskervilles03', ph = 21):\n",
        "  sent_feat = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  sent_doc = nlp(sentence)\n",
        "  tokens = tokenize(sent_doc, ch, ph)\n",
        "  lengths = len_path_root(tokens)\n",
        "\n",
        "  ord = 0\n",
        "  shift = 0\n",
        "  for tok in tokens:\n",
        "\n",
        "    if keep(tok) or is_test:\n",
        "      features = word2feature(tok)\n",
        "      #features['len_path_root'] = lengths[tok]\n",
        "      sent_feat.append(features)\n",
        "\n",
        "    else:\n",
        "      labels = np.delete(labels, ord-shift)\n",
        "      shift+=1\n",
        "\n",
        "    ord+=1\n",
        "\n",
        "  return sent_feat, labels\n",
        "\n",
        "\n",
        "#takes the table as an input\n",
        "#is_test makes the preporcessing function keep all entries in case of test data\n",
        "#returns the list of lists of dicitionaries with the features\n",
        "\n",
        "#text->phrase->words->dict of features\n",
        "#dict of feat->list of dicts->list of lists of dicts\n",
        "def process_data(table, is_test):\n",
        "  all_ch_ids = table['chapter_id'].unique()\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "  for ch in all_ch_ids:\n",
        "    filter_ch = table[table['chapter_id'] == ch]\n",
        "    all_ph_ids = filter_ch['phrase_id'].unique()\n",
        "    for ph in all_ph_ids:\n",
        "      phrase = get_text(table, ph, ch)\n",
        "      labels = get_labels(table, ph, ch)\n",
        "      #filtered\n",
        "      #print(ch,ph)\n",
        "      filt_features, filt_labels = sent2feature(phrase, labels, is_test, ch, ph)\n",
        "      all_features.append(filt_features)\n",
        "      all_labels.append(filt_labels)\n",
        "\n",
        "  return all_features, all_labels\n",
        "\n",
        "#solving exceptions in data\n",
        "def filter(x,y):\n",
        "  count = 0\n",
        "  new_y = []\n",
        "  for sent,lab in zip(x, y):\n",
        "    if len(sent) != len(lab):\n",
        "      count+=1\n",
        "      lab = np.delete(lab, len(lab)-1)\n",
        "    new_y.append(lab)\n",
        "  print(count)\n",
        "  return new_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing code"
      ],
      "metadata": {
        "id": "JEX7l7tQTeYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFoTgU82rvD1",
        "outputId": "edd07df0-d1ae-469e-d776-025e5c526ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train), len(y_train))\n",
        "print(len(x_test), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekJAulp2UkmA",
        "outputId": "7dc61045-3143-4c50-8be5-f22dee945fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3644 3644\n",
            "787 787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # for word in sent:\n",
        "  #   for feat in word:\n",
        "  #     if :\n",
        "  #       print(word, feat)\n",
        "  #       break"
      ],
      "metadata": {
        "id": "KOuWzYSCPbMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK2JFA2nUKmu"
      },
      "outputs": [],
      "source": [
        "#counting B-Neg from dataset\n",
        "count = 0\n",
        "for sent in y_train:\n",
        "  for tok in sent:\n",
        "    if tok == 'B-NEG':\n",
        "      count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate through tokens of sentence\n",
        "doc = nlp(\"I don't like apples and pasta.\")\n",
        "for tok in doc:\n",
        "  print(isinstance(tok, spacy.tokens.token.Token))"
      ],
      "metadata": {
        "id": "VJF7g4baGBEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictio = {'text': 'back',\n",
        "          'lemma': 'back',\n",
        "          'fine_pos': 'NOUN',\n",
        "          'coarse_pos': 'NN',\n",
        "          'dependency': 'pobj',\n",
        "          'head': 'with',\n",
        "          'suffix': 0,\n",
        "          'prefix': 0,\n",
        "          'len_path_root': 2}\n",
        "\n",
        "for key in dictio:\n",
        "  print(key,' : ' ,dictio[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gim8JSEyjZkw",
        "outputId": "e0dc9c5a-9b2b-44cc-b7a8-48f3b99f67a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text  :  back\n",
            "lemma  :  back\n",
            "fine_pos  :  NOUN\n",
            "coarse_pos  :  NN\n",
            "dependency  :  pobj\n",
            "head  :  with\n",
            "suffix  :  0\n",
            "prefix  :  0\n",
            "len_path_root  :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIqDLgqrVXS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840b7069-89ce-471d-d294-3c5ec323bb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now ADV\n",
            ", PUNCT\n",
            "all DET\n",
            "these DET\n",
            "rooms NOUN\n",
            "are AUX\n",
            "unfurnished VERB\n",
            "and CCONJ\n",
            "unoccupied ADJ\n",
            "so SCONJ\n",
            "that SCONJ\n",
            "his PRON\n",
            "expedition NOUN\n",
            "became VERB\n",
            "more ADV\n",
            "mysterious ADJ\n",
            "than ADP\n",
            "ever ADV\n",
            ". PUNCT\n",
            "{'text': 'Now', 'lemma': 'now', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'advmod', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': ',', 'lemma': ',', 'fine_pos': 'PUNCT', 'coarse_pos': ',', 'dependency': 'punct', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'all', 'lemma': 'all', 'fine_pos': 'DET', 'coarse_pos': 'PDT', 'dependency': 'predet', 'head': 'rooms', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'these', 'lemma': 'these', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'head': 'rooms', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'rooms', 'lemma': 'room', 'fine_pos': 'NOUN', 'coarse_pos': 'NNS', 'dependency': 'nsubjpass', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'are', 'lemma': 'be', 'fine_pos': 'AUX', 'coarse_pos': 'VBP', 'dependency': 'auxpass', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'unfurnished', 'lemma': 'unfurnishe', 'fine_pos': 'VERB', 'coarse_pos': 'VBN', 'dependency': 'ROOT', 'head': 'unfurnished', 'suffix': 0, 'prefix': 1, 'len_path_root': 0} \n",
            "\n",
            "{'text': 'and', 'lemma': 'and', 'fine_pos': 'CCONJ', 'coarse_pos': 'CC', 'dependency': 'cc', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'unoccupied', 'lemma': 'unoccupied', 'fine_pos': 'ADJ', 'coarse_pos': 'JJ', 'dependency': 'conj', 'head': 'unfurnished', 'suffix': 0, 'prefix': 1, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'so', 'lemma': 'so', 'fine_pos': 'SCONJ', 'coarse_pos': 'IN', 'dependency': 'mark', 'head': 'became', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'that', 'lemma': 'that', 'fine_pos': 'SCONJ', 'coarse_pos': 'IN', 'dependency': 'mark', 'head': 'became', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'his', 'lemma': 'his', 'fine_pos': 'PRON', 'coarse_pos': 'PRP$', 'dependency': 'poss', 'head': 'expedition', 'suffix': 0, 'prefix': 0, 'len_path_root': 3} \n",
            "\n",
            "{'text': 'expedition', 'lemma': 'expedition', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'nsubj', 'head': 'became', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'became', 'lemma': 'become', 'fine_pos': 'VERB', 'coarse_pos': 'VBD', 'dependency': 'advcl', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n",
            "{'text': 'more', 'lemma': 'more', 'fine_pos': 'ADV', 'coarse_pos': 'RBR', 'dependency': 'advmod', 'head': 'mysterious', 'suffix': 0, 'prefix': 0, 'len_path_root': 3} \n",
            "\n",
            "{'text': 'mysterious', 'lemma': 'mysterious', 'fine_pos': 'ADJ', 'coarse_pos': 'JJ', 'dependency': 'acomp', 'head': 'became', 'suffix': 0, 'prefix': 0, 'len_path_root': 2} \n",
            "\n",
            "{'text': 'than', 'lemma': 'than', 'fine_pos': 'ADP', 'coarse_pos': 'IN', 'dependency': 'prep', 'head': 'mysterious', 'suffix': 0, 'prefix': 0, 'len_path_root': 3} \n",
            "\n",
            "{'text': 'ever', 'lemma': 'ever', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'pcomp', 'head': 'than', 'suffix': 0, 'prefix': 0, 'len_path_root': 4} \n",
            "\n",
            "{'text': '.', 'lemma': '.', 'fine_pos': 'PUNCT', 'coarse_pos': '.', 'dependency': 'punct', 'head': 'unfurnished', 'suffix': 0, 'prefix': 0, 'len_path_root': 1} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#extracting features for a single sentence\n",
        "phr1 = get_text(train_data, 121, 'baskervilles08')\n",
        "lab1 = get_labels(train_data, 121, 'baskervilles08')\n",
        "doc = nlp(phr1)\n",
        "doc = tokenize(doc)\n",
        "\n",
        "#printing tokens\n",
        "for tok in doc:\n",
        "  print(tok.text, tok.pos_)\n",
        "\n",
        "#printing extracted features\n",
        "ld = sent2feature(phr1, lab1, 'baskervilles08', 121)\n",
        "for word_dict in ld[0]:\n",
        "  print(word_dict, '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRF tutorial with original code"
      ],
      "metadata": {
        "id": "_qYZR8KdAIKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "metadata": {
        "id": "crhX1ImazeoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('conll2002')\n",
        "nltk.corpus.conll2002.fileids()\n",
        "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "Y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "Y_test = [sent2labels(s) for s in test_sents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4wFLUZVzUeG",
        "outputId": "809847ff-f45e-42fc-ad28-15351a8dbc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2002 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train[7])"
      ],
      "metadata": {
        "id": "oa-7TOjF4z2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[7])"
      ],
      "metadata": {
        "id": "Ia613-BS5ILI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X_train[7])\n",
        "for feat in X_train[7]:\n",
        "  print(feat)"
      ],
      "metadata": {
        "id": "IFs2eTVl0LwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feat in x_train[1]:\n",
        "  print(feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b1TOR7j2QBr",
        "outputId": "2201be57-7944-407c-e2b4-0df0f736c5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bias': 1.0, 'text': 'Mr.', 'lemma': 'Mr.', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'compound', 'head': Holmes, 'suffix': 0, 'prefix': 0, 'len_path_root': 2}\n",
            "{'bias': 1.0, 'text': 'Sherlock', 'lemma': 'Sherlock', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'compound', 'head': Holmes, 'suffix': 0, 'prefix': 0, 'len_path_root': 2}\n",
            "{'bias': 1.0, 'text': 'Holmes', 'lemma': 'Holmes', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'nsubj', 'head': save, 'suffix': 0, 'prefix': 0, 'len_path_root': 1}\n",
            "{'bias': 1.0, 'text': 'usually', 'lemma': 'usually', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'advmod', 'head': was, 'suffix': 0, 'prefix': 0, 'len_path_root': 3}\n",
            "{'bias': 1.0, 'text': 'late', 'lemma': 'late', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'acomp', 'head': was, 'suffix': 0, 'prefix': 0, 'len_path_root': 3}\n",
            "{'bias': 1.0, 'text': 'the', 'lemma': 'the', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'head': mornings, 'suffix': 0, 'prefix': 0, 'len_path_root': 5}\n",
            "{'bias': 1.0, 'text': 'mornings', 'lemma': 'morning', 'fine_pos': 'NOUN', 'coarse_pos': 'NNS', 'dependency': 'pobj', 'head': in, 'suffix': 0, 'prefix': 0, 'len_path_root': 4}\n",
            "{'bias': 1.0, 'text': 'save', 'lemma': 'save', 'fine_pos': 'VERB', 'coarse_pos': 'VB', 'dependency': 'ROOT', 'head': save, 'suffix': 0, 'prefix': 0, 'len_path_root': 0}\n",
            "{'bias': 1.0, 'text': 'not', 'lemma': 'not', 'fine_pos': 'PART', 'coarse_pos': 'RB', 'dependency': 'neg', 'head': occasions, 'suffix': 0, 'prefix': 0, 'len_path_root': 3}\n",
            "{'bias': 1.0, 'text': 'infrequent', 'lemma': 'infrequent', 'fine_pos': 'ADJ', 'coarse_pos': 'JJ', 'dependency': 'amod', 'head': occasions, 'suffix': 0, 'prefix': 1, 'len_path_root': 3}\n",
            "{'bias': 1.0, 'text': 'occasions', 'lemma': 'occasion', 'fine_pos': 'NOUN', 'coarse_pos': 'NNS', 'dependency': 'pobj', 'head': upon, 'suffix': 0, 'prefix': 0, 'len_path_root': 2}\n",
            "{'bias': 1.0, 'text': 'night', 'lemma': 'night', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'npadvmod', 'head': was, 'suffix': 0, 'prefix': 0, 'len_path_root': 2}\n",
            "{'bias': 1.0, 'text': 'seated', 'lemma': 'seat', 'fine_pos': 'VERB', 'coarse_pos': 'VBN', 'dependency': 'conj', 'head': save, 'suffix': 0, 'prefix': 0, 'len_path_root': 1}\n",
            "{'bias': 1.0, 'text': 'the', 'lemma': 'the', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'head': table, 'suffix': 0, 'prefix': 0, 'len_path_root': 4}\n",
            "{'bias': 1.0, 'text': 'breakfast', 'lemma': 'breakfast', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'compound', 'head': table, 'suffix': 0, 'prefix': 0, 'len_path_root': 4}\n",
            "{'bias': 1.0, 'text': 'table', 'lemma': 'table', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'pobj', 'head': at, 'suffix': 0, 'prefix': 0, 'len_path_root': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline model"
      ],
      "metadata": {
        "id": "PHS2lTRWuhgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#given dictionary of features of a token\n",
        "#output label->B/\n",
        "def get_pred(features_dict):\n",
        "\n",
        "  text_from = features_dict['text']\n",
        "  neg_list = ['nor', 'Nor', 'neither', 'Neither', 'without', 'Without', 'nobody', 'Nobody', 'none', 'None', 'nothing', 'Nothing',\n",
        "              'never', 'not', 'no', 'Never', 'Not', 'No', 'nowhere', 'non', 'Nowhere', 'Non', \"n't\", \"rather\", \"than\", 'for', 'the']\n",
        "\n",
        "  if text_from in neg_list:\n",
        "    return 'B-NEG'\n",
        "\n",
        "  if features_dict['suffix'] == 1 or features_dict['prefix'] == 1:\n",
        "   return 'B-NEG'\n",
        "  return 'O'\n",
        ""
      ],
      "metadata": {
        "id": "mqEYF831ufqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing CRF model"
      ],
      "metadata": {
        "id": "u4mqruSLxCVO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y-kxBedey9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf09e627-c821-4284-fb53-0a3ce0798a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "#data final form\n",
        "x_train, y_trainin = process_data(train_data, False)\n",
        "x_test, y_test = process_data(dev, True)\n",
        "\n",
        "y_train = filter(x_train,y_trainin)\n",
        "y_test = filter(x_test,y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc8ZqsTyu3-7",
        "outputId": "e283388c-a951-4bac-b411-c797ab9cdfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'Mr.', 'lemma': 'Mr.', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'compound', 'suffix': 0, 'prefix': 0}, {'text': 'Sherlock', 'lemma': 'Sherlock', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'compound', 'suffix': 0, 'prefix': 0}, {'text': 'Holmes', 'lemma': 'Holmes', 'fine_pos': 'PROPN', 'coarse_pos': 'NNP', 'dependency': 'nsubj', 'suffix': 0, 'prefix': 0}, {'text': 'who', 'lemma': 'who', 'fine_pos': 'PRON', 'coarse_pos': 'WP', 'dependency': 'nsubj', 'suffix': 0, 'prefix': 0}, {'text': 'was', 'lemma': 'be', 'fine_pos': 'AUX', 'coarse_pos': 'VBD', 'dependency': 'relcl', 'suffix': 0, 'prefix': 0}, {'text': 'usually', 'lemma': 'usually', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'advmod', 'suffix': 0, 'prefix': 0}, {'text': 'very', 'lemma': 'very', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'advmod', 'suffix': 0, 'prefix': 0}, {'text': 'late', 'lemma': 'late', 'fine_pos': 'ADJ', 'coarse_pos': 'JJ', 'dependency': 'acomp', 'suffix': 0, 'prefix': 0}, {'text': 'in', 'lemma': 'in', 'fine_pos': 'ADP', 'coarse_pos': 'IN', 'dependency': 'prep', 'suffix': 0, 'prefix': 1}, {'text': 'the', 'lemma': 'the', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'suffix': 0, 'prefix': 0}, {'text': 'mornings', 'lemma': 'morning', 'fine_pos': 'NOUN', 'coarse_pos': 'NNS', 'dependency': 'pobj', 'suffix': 0, 'prefix': 0}, {'text': 'save', 'lemma': 'save', 'fine_pos': 'VERB', 'coarse_pos': 'VB', 'dependency': 'nsubjpass', 'suffix': 0, 'prefix': 0}, {'text': 'upon', 'lemma': 'upon', 'fine_pos': 'SCONJ', 'coarse_pos': 'IN', 'dependency': 'prep', 'suffix': 0, 'prefix': 0}, {'text': 'those', 'lemma': 'those', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'suffix': 0, 'prefix': 0}, {'text': 'not', 'lemma': 'not', 'fine_pos': 'PART', 'coarse_pos': 'RB', 'dependency': 'neg', 'suffix': 0, 'prefix': 0}, {'text': 'infrequent', 'lemma': 'infrequent', 'fine_pos': 'ADJ', 'coarse_pos': 'JJ', 'dependency': 'amod', 'suffix': 0, 'prefix': 1}, {'text': 'occasions', 'lemma': 'occasion', 'fine_pos': 'NOUN', 'coarse_pos': 'NNS', 'dependency': 'pobj', 'suffix': 0, 'prefix': 0}, {'text': 'when', 'lemma': 'when', 'fine_pos': 'SCONJ', 'coarse_pos': 'WRB', 'dependency': 'advmod', 'suffix': 0, 'prefix': 0}, {'text': 'he', 'lemma': 'he', 'fine_pos': 'PRON', 'coarse_pos': 'PRP', 'dependency': 'nsubj', 'suffix': 0, 'prefix': 0}, {'text': 'was', 'lemma': 'be', 'fine_pos': 'AUX', 'coarse_pos': 'VBD', 'dependency': 'advcl', 'suffix': 0, 'prefix': 0}, {'text': 'up', 'lemma': 'up', 'fine_pos': 'ADV', 'coarse_pos': 'RB', 'dependency': 'advmod', 'suffix': 0, 'prefix': 0}, {'text': 'all', 'lemma': 'all', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'suffix': 0, 'prefix': 0}, {'text': 'night', 'lemma': 'night', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'npadvmod', 'suffix': 0, 'prefix': 0}, {'text': 'was', 'lemma': 'be', 'fine_pos': 'AUX', 'coarse_pos': 'VBD', 'dependency': 'auxpass', 'suffix': 0, 'prefix': 0}, {'text': 'seated', 'lemma': 'seat', 'fine_pos': 'VERB', 'coarse_pos': 'VBN', 'dependency': 'ROOT', 'suffix': 0, 'prefix': 0}, {'text': 'at', 'lemma': 'at', 'fine_pos': 'ADP', 'coarse_pos': 'IN', 'dependency': 'prep', 'suffix': 0, 'prefix': 0}, {'text': 'the', 'lemma': 'the', 'fine_pos': 'DET', 'coarse_pos': 'DT', 'dependency': 'det', 'suffix': 0, 'prefix': 0}, {'text': 'breakfast', 'lemma': 'breakfast', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'compound', 'suffix': 0, 'prefix': 0}, {'text': 'table', 'lemma': 'table', 'fine_pos': 'NOUN', 'coarse_pos': 'NN', 'dependency': 'pobj', 'suffix': 0, 'prefix': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline results"
      ],
      "metadata": {
        "id": "cNaMT_g9vmX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, unf_ytest = process_data(test_data, True)\n",
        "y_test = filter(x_test,unf_ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pWUtpKs5LGJ",
        "outputId": "995a2e47-004b-4829-83ca-306b03ea73f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_base=[]#final output -> list of lists of chars\n",
        "for phrase in x_test:\n",
        "  y_hat_phrase=[]\n",
        "  for word in phrase:\n",
        "    y_hat_phrase.append(get_pred(word))\n",
        "  y_hat_base.append(y_hat_phrase)"
      ],
      "metadata": {
        "id": "tsF0uu0CvmEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_hat_base))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfFamOSF2cd-",
        "outputId": "32722fc1-c134-4af3-a29d-32c50c7ade0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "787\n",
            "787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_hat_base[1]))\n",
        "print(len(y_test[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNg_UxVs2uVh",
        "outputId": "67195d88-0b68-4be0-b0ab-759dc41a5a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_test)):\n",
        "  if len(y_test[i])!=len(y_hat_base[i]):\n",
        "    print(\"check again\")\n"
      ],
      "metadata": {
        "id": "LouY-Q553c8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['O', 'B-NEG', 'I-NEG']\n",
        "metrics.flat_f1_score(y_test, y_hat_base, average='weighted', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhsjjghv3-C4",
        "outputId": "41c501cd-2390-401a-d4ff-7c4893650463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9527520340050186"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_hat_base, labels=sorted_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52I2OCcB4F_R",
        "outputId": "f3bcecdd-3cc7-485f-dd6b-18b1ed2fa5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.999     0.929     0.963     18915\n",
            "       B-NEG      0.161     0.967     0.276       269\n",
            "       I-NEG      0.000     0.000     0.000         5\n",
            "\n",
            "    accuracy                          0.929     19189\n",
            "   macro avg      0.387     0.632     0.413     19189\n",
            "weighted avg      0.987     0.929     0.953     19189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1"
      ],
      "metadata": {
        "id": "ih0j55T1biau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='l2sgd',\n",
        "    c2=0.1,\n",
        "    max_iterations=1000,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "dbMuIqv2xdNF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "b81507c3-d627-449d-e003-30544a56881b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='l2sgd', all_possible_transitions=True, c2=0.1,\n",
              "    max_iterations=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;l2sgd&#x27;, all_possible_transitions=True, c2=0.1,\n",
              "    max_iterations=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;l2sgd&#x27;, all_possible_transitions=True, c2=0.1,\n",
              "    max_iterations=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['O', 'B-NEG', 'I-NEG']\n",
        "y_pred = crf.predict(x_test)\n",
        "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9AVf2MVqsX7",
        "outputId": "6bb821ea-f893-4db2-c30e-2d789fe01250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9975257255186872"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJgUmTpi7BIp",
        "outputId": "1faba2ad-12ff-4b81-c3e2-6461bee5c6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.998     0.999     0.999     13385\n",
            "       B-NEG      0.934     0.881     0.906       176\n",
            "       I-NEG      1.000     0.667     0.800         3\n",
            "\n",
            "    accuracy                          0.998     13564\n",
            "   macro avg      0.977     0.849     0.902     13564\n",
            "weighted avg      0.998     0.998     0.998     13564\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2"
      ],
      "metadata": {
        "id": "XhiEkXlkbbF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "G1PW4syxbNZC",
        "outputId": "50b19d8a-c038-41ef-a514-2b4a09781ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=0.1, c2=0.1,\n",
              "    max_iterations=100)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['O', 'B-NEG', 'I-NEG']\n",
        "y_pred = crf.predict(x_test)\n",
        "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVuoC404bWED",
        "outputId": "08c8e1df-553c-4f4f-8f0f-36fe7f9e8879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9972982039350066"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu_3A2GobVQK",
        "outputId": "15c9518d-3882-4846-afcb-b13d601b17f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.999     0.999     0.999     13385\n",
            "       B-NEG      0.908     0.892     0.900       176\n",
            "       I-NEG      1.000     0.333     0.500         3\n",
            "\n",
            "    accuracy                          0.997     13564\n",
            "   macro avg      0.969     0.741     0.799     13564\n",
            "weighted avg      0.997     0.997     0.997     13564\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning on model 2"
      ],
      "metadata": {
        "id": "HdkihGi-cNDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['O', 'B-NEG', 'I-NEG']\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score, average='weighted', labels=labels)\n",
        "\n",
        "# search 100 iter\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=5,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=100,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "gMpqaP7DcPND",
        "outputId": "fa6f497f-5c38-46a9-a87f-2f66945597ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=CRF(algorithm='lbfgs',\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719d14ffa0>,\n",
              "                                        'c2': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719cf714f0>},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['O', 'B-NEG', 'I-NEG']),\n",
              "                   verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719d14ffa0&gt;,\n",
              "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719cf714f0&gt;},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=[&#x27;O&#x27;, &#x27;B-NEG&#x27;, &#x27;I-NEG&#x27;]),\n",
              "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
              "                   estimator=CRF(algorithm=&#x27;lbfgs&#x27;,\n",
              "                                 all_possible_transitions=True,\n",
              "                                 max_iterations=100),\n",
              "                   n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={&#x27;c1&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719d14ffa0&gt;,\n",
              "                                        &#x27;c2&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f719cf714f0&gt;},\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=[&#x27;O&#x27;, &#x27;B-NEG&#x27;, &#x27;I-NEG&#x27;]),\n",
              "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, max_iterations=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, max_iterations=100)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMZ400qqeNea",
        "outputId": "09eda351-fbd5-4e22-d4fc-9729c987cb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best params: {'c1': 0.116733206155079, 'c2': 0.025018142042647337}\n",
            "best CV score: 0.9967958620097324\n",
            "model size: 0.05M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final testing set - We will use hypertuned model from above"
      ],
      "metadata": {
        "id": "p5RWWHAVcHVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, unf_ytest = process_data(test_data, True)\n",
        "y_test = filter(x_test,unf_ytest)"
      ],
      "metadata": {
        "id": "mt9HqBZkhfhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f4d06a-4250-4418-be13-a62cb9a0cabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(x_test)\n",
        "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM4_NzlfUWOL",
        "outputId": "f76efda5-b1ba-46ee-a150-7063311d61d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.998     0.998     0.998     18915\n",
            "       B-NEG      0.865     0.907     0.886       269\n",
            "       I-NEG      0.000     0.000     0.000         5\n",
            "\n",
            "    accuracy                          0.997     19189\n",
            "   macro avg      0.621     0.635     0.628     19189\n",
            "weighted avg      0.996     0.997     0.996     19189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(7))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-7:])"
      ],
      "metadata": {
        "id": "6PDhSQvd9qWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f3f164-24f2-4b0d-9a34-03bb0a0acd22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top positive:\n",
            "7.492896 B-NEG    lemma:nowhere\n",
            "5.715529 B-NEG    lemma:nor\n",
            "5.611259 O        fine_pos:VERB\n",
            "5.003009 O        fine_pos:AUX\n",
            "4.920772 O        fine_pos:NOUN\n",
            "4.903639 B-NEG    suffix\n",
            "4.858742 O        fine_pos:PRON\n",
            "\n",
            "Top negative:\n",
            "-3.260833 O        lemma:without\n",
            "-3.309972 O        text:no\n",
            "-3.491863 O        prefix\n",
            "-3.680448 O        lemma:never\n",
            "-4.100059 B-NEG    fine_pos:NOUN\n",
            "-4.887205 O        suffix\n",
            "-5.193294 B-NEG    fine_pos:ADV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis"
      ],
      "metadata": {
        "id": "ZcA09DsWK_Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#solving exceptions in data\n",
        "#unf, Y_pred\n",
        "def restore(x,y):\n",
        "  count = 0\n",
        "  new_y = []\n",
        "  for sent,lab in zip(x, y):\n",
        "    if len(sent) != len(lab):\n",
        "      lab = np.insert(lab, len(lab),'O')\n",
        "    new_y.append(lab)\n",
        "  return new_y\n",
        "def merged(my_list):\n",
        "  new_format=[]\n",
        "  for llist in my_list:\n",
        "    for el in llist:\n",
        "      new_format.append(el)\n",
        "  new_format = np.array(new_format)\n",
        "  return new_format\n",
        "\n",
        "#lengths y_pred = x_test = y_test\n",
        "# print(len(test_data))\n",
        "\n",
        "# count = 0\n",
        "# for prop in x_test:\n",
        "#   for word in prop:\n",
        "#     count+=1\n",
        "# print(count)"
      ],
      "metadata": {
        "id": "THsFlezOfcjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = restore(unf_ytest, y_pred)\n",
        "outputs = merged(y_pred)\n",
        "test_data['prediction'] = outputs\n",
        "non_match = test_data[test_data['prediction'] != test_data['label']]\n",
        "false_neg = non_match[(non_match['prediction']=='O') & (non_match['label']=='B-NEG')]\n",
        "false_pos = non_match[(non_match['label']=='O') & (non_match['prediction']=='B-NEG')]"
      ],
      "metadata": {
        "id": "KV3aIqqar4si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(false_neg))\n",
        "print(len(false_pos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zesaUL6zQoSr",
        "outputId": "3c095247-a9b9-4b6e-e614-53fbe93f86ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(false_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AYJRmMCkgnEA",
        "outputId": "2c485172-acee-4524-9b4a-82eca331c6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     chapter_id  phrase_id  word_id           word label prediction\n",
              "52    cardboard          1        5  unfortunately     O      B-NEG\n",
              "2601  cardboard        127       12         intact     O      B-NEG\n",
              "2789  cardboard        140       11        nothing     O      B-NEG\n",
              "4518  cardboard        233       12        nothing     O      B-NEG\n",
              "4985  cardboard        261       14        nothing     O      B-NEG\n",
              "6967  cardboard        353       30            not     O      B-NEG\n",
              "7476  cardboard        376        3        without     O      B-NEG\n",
              "7613  cardboard        382       25          never     O      B-NEG\n",
              "7961  cardboard        395       30            had     O      B-NEG\n",
              "8028  cardboard        401        2            n't     O      B-NEG\n",
              "8035  cardboard        401        9        without     O      B-NEG\n",
              "8348  cardboard        413        8      irritable     O      B-NEG\n",
              "8356  cardboard        413       16        nothing     O      B-NEG\n",
              "8941  cardboard        441        5             do     O      B-NEG\n",
              "9140  cardboard        448        8          could     O      B-NEG\n",
              "9345  cardboard        454       20            was     O      B-NEG\n",
              "7      circle01          0        7            can     O      B-NEG\n",
              "16     circle01          0       16            for     O      B-NEG\n",
              "18     circle01          0       18              ,     O      B-NEG\n",
              "1080   circle01         70        1            not     O      B-NEG\n",
              "1213   circle01         81        6            not     O      B-NEG\n",
              "2176   circle01        151       11        without     O      B-NEG\n",
              "2332   circle01        166        6            not     O      B-NEG\n",
              "3352   circle01        244       23           fail     O      B-NEG\n",
              "3790   circle01        271       11            not     O      B-NEG\n",
              "4732   circle01        353        5            n't     O      B-NEG\n",
              "5616   circle02         45       11            not     O      B-NEG\n",
              "6566   circle02        101        6            not     O      B-NEG\n",
              "6576   circle02        103        2            not     O      B-NEG\n",
              "7214   circle02        139        7        nothing     O      B-NEG\n",
              "7509   circle02        152        0            Not     O      B-NEG\n",
              "7655   circle02        162        7       listless     O      B-NEG\n",
              "7660   circle02        162       12        endless     O      B-NEG\n",
              "8274   circle02        189        2        refused     O      B-NEG\n",
              "8305   circle02        190       15        prevent     O      B-NEG\n",
              "8597   circle02        202       15       ruthless     O      B-NEG\n",
              "8769   circle02        210       27        nothing     O      B-NEG"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a99963b1-c632-4024-b057-7babcaf0f905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chapter_id</th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>word_id</th>\n",
              "      <th>word</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>unfortunately</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2601</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>127</td>\n",
              "      <td>12</td>\n",
              "      <td>intact</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2789</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>140</td>\n",
              "      <td>11</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4518</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>233</td>\n",
              "      <td>12</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4985</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>261</td>\n",
              "      <td>14</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6967</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>353</td>\n",
              "      <td>30</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7476</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>376</td>\n",
              "      <td>3</td>\n",
              "      <td>without</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7613</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>382</td>\n",
              "      <td>25</td>\n",
              "      <td>never</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7961</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>395</td>\n",
              "      <td>30</td>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8028</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>401</td>\n",
              "      <td>2</td>\n",
              "      <td>n't</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8035</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>401</td>\n",
              "      <td>9</td>\n",
              "      <td>without</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8348</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>413</td>\n",
              "      <td>8</td>\n",
              "      <td>irritable</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8356</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>413</td>\n",
              "      <td>16</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8941</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>441</td>\n",
              "      <td>5</td>\n",
              "      <td>do</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9140</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>448</td>\n",
              "      <td>8</td>\n",
              "      <td>could</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9345</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>454</td>\n",
              "      <td>20</td>\n",
              "      <td>was</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>can</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>for</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>circle01</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1213</th>\n",
              "      <td>circle01</td>\n",
              "      <td>81</td>\n",
              "      <td>6</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2176</th>\n",
              "      <td>circle01</td>\n",
              "      <td>151</td>\n",
              "      <td>11</td>\n",
              "      <td>without</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2332</th>\n",
              "      <td>circle01</td>\n",
              "      <td>166</td>\n",
              "      <td>6</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3352</th>\n",
              "      <td>circle01</td>\n",
              "      <td>244</td>\n",
              "      <td>23</td>\n",
              "      <td>fail</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3790</th>\n",
              "      <td>circle01</td>\n",
              "      <td>271</td>\n",
              "      <td>11</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>circle01</td>\n",
              "      <td>353</td>\n",
              "      <td>5</td>\n",
              "      <td>n't</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5616</th>\n",
              "      <td>circle02</td>\n",
              "      <td>45</td>\n",
              "      <td>11</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6566</th>\n",
              "      <td>circle02</td>\n",
              "      <td>101</td>\n",
              "      <td>6</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6576</th>\n",
              "      <td>circle02</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7214</th>\n",
              "      <td>circle02</td>\n",
              "      <td>139</td>\n",
              "      <td>7</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7509</th>\n",
              "      <td>circle02</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>Not</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7655</th>\n",
              "      <td>circle02</td>\n",
              "      <td>162</td>\n",
              "      <td>7</td>\n",
              "      <td>listless</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7660</th>\n",
              "      <td>circle02</td>\n",
              "      <td>162</td>\n",
              "      <td>12</td>\n",
              "      <td>endless</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8274</th>\n",
              "      <td>circle02</td>\n",
              "      <td>189</td>\n",
              "      <td>2</td>\n",
              "      <td>refused</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8305</th>\n",
              "      <td>circle02</td>\n",
              "      <td>190</td>\n",
              "      <td>15</td>\n",
              "      <td>prevent</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8597</th>\n",
              "      <td>circle02</td>\n",
              "      <td>202</td>\n",
              "      <td>15</td>\n",
              "      <td>ruthless</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8769</th>\n",
              "      <td>circle02</td>\n",
              "      <td>210</td>\n",
              "      <td>27</td>\n",
              "      <td>nothing</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NEG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a99963b1-c632-4024-b057-7babcaf0f905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a99963b1-c632-4024-b057-7babcaf0f905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a99963b1-c632-4024-b057-7babcaf0f905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "PItkSvNpXWMq",
        "outputId": "9f8f48b9-55df-4f20-d146-adce45f02616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      chapter_id  phrase_id  word_id          word  label prediction\n",
              "347    cardboard         12       32      unsolved  B-NEG          O\n",
              "589    cardboard         23       17   incredulity  B-NEG          O\n",
              "669    cardboard         27        4           far  B-NEG          O\n",
              "751    cardboard         31        5     injustice  B-NEG          O\n",
              "904    cardboard         41        6      unframed  B-NEG          O\n",
              "3317   cardboard        167        9   discoloured  B-NEG          O\n",
              "6238   cardboard        322       29   undoubtedly  B-NEG          O\n",
              "6480   cardboard        331        1  unsuccessful  B-NEG          O\n",
              "7962   cardboard        395       31         never  B-NEG          O\n",
              "8353   cardboard        413       13     ceaseless  B-NEG          O\n",
              "8377   cardboard        415       11   inseparable  B-NEG          O\n",
              "8833   cardboard        436        2           not  B-NEG          O\n",
              "8942   cardboard        441        6           n't  B-NEG          O\n",
              "9141   cardboard        448        9           not  B-NEG          O\n",
              "9346   cardboard        454       21           not  B-NEG          O\n",
              "10157  cardboard        493       18   unthinkable  B-NEG          O\n",
              "8       circle01          0        8           not  B-NEG          O\n",
              "17      circle01          0       17    uneasiness  B-NEG          O\n",
              "19      circle01          0       19           nor  B-NEG          O\n",
              "1452    circle01        104       11    absolutely  B-NEG          O\n",
              "2141    circle01        149       15       unusual  B-NEG          O\n",
              "7638    circle02        161        7            no  B-NEG          O\n",
              "7711    circle02        164        7       dislike  B-NEG          O\n",
              "7725    circle02        165       12       dislike  B-NEG          O\n",
              "8175    circle02        182        3     senseless  B-NEG          O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa677442-80e5-4f06-955c-577940360638\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chapter_id</th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>word_id</th>\n",
              "      <th>word</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>12</td>\n",
              "      <td>32</td>\n",
              "      <td>unsolved</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>incredulity</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>far</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>injustice</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>unframed</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3317</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>167</td>\n",
              "      <td>9</td>\n",
              "      <td>discoloured</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6238</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>322</td>\n",
              "      <td>29</td>\n",
              "      <td>undoubtedly</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6480</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>331</td>\n",
              "      <td>1</td>\n",
              "      <td>unsuccessful</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7962</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>395</td>\n",
              "      <td>31</td>\n",
              "      <td>never</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8353</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>413</td>\n",
              "      <td>13</td>\n",
              "      <td>ceaseless</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8377</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>415</td>\n",
              "      <td>11</td>\n",
              "      <td>inseparable</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8833</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>436</td>\n",
              "      <td>2</td>\n",
              "      <td>not</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8942</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>441</td>\n",
              "      <td>6</td>\n",
              "      <td>n't</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9141</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>448</td>\n",
              "      <td>9</td>\n",
              "      <td>not</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9346</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>454</td>\n",
              "      <td>21</td>\n",
              "      <td>not</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10157</th>\n",
              "      <td>cardboard</td>\n",
              "      <td>493</td>\n",
              "      <td>18</td>\n",
              "      <td>unthinkable</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>not</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>uneasiness</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>circle01</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>nor</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>circle01</td>\n",
              "      <td>104</td>\n",
              "      <td>11</td>\n",
              "      <td>absolutely</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2141</th>\n",
              "      <td>circle01</td>\n",
              "      <td>149</td>\n",
              "      <td>15</td>\n",
              "      <td>unusual</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7638</th>\n",
              "      <td>circle02</td>\n",
              "      <td>161</td>\n",
              "      <td>7</td>\n",
              "      <td>no</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7711</th>\n",
              "      <td>circle02</td>\n",
              "      <td>164</td>\n",
              "      <td>7</td>\n",
              "      <td>dislike</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7725</th>\n",
              "      <td>circle02</td>\n",
              "      <td>165</td>\n",
              "      <td>12</td>\n",
              "      <td>dislike</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8175</th>\n",
              "      <td>circle02</td>\n",
              "      <td>182</td>\n",
              "      <td>3</td>\n",
              "      <td>senseless</td>\n",
              "      <td>B-NEG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa677442-80e5-4f06-955c-577940360638')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa677442-80e5-4f06-955c-577940360638 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa677442-80e5-4f06-955c-577940360638');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "prvWX5nNORf4",
        "Dyc_QQ8XSKgt",
        "X7d-MsmDOeCX",
        "JcQPgzSOkyCZ",
        "RR5-pL5miPhX",
        "JEX7l7tQTeYY",
        "_qYZR8KdAIKq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}